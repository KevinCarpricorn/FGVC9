{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_dir = './'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "if not os.path.exists('./train'):\n",
    "    os.mkdir('./train')\n",
    "if not os.path.exists('./vali'):\n",
    "    os.mkdir('./vali')\n",
    "if not os.path.exists('./train_vali'):\n",
    "    os.mkdir('./train_vali')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'train_cultivar_mapping.csv'), 'r') as f:\n",
    "    train_cultivar_mapping = pd.read_csv(f)\n",
    "    labels = train_cultivar_mapping['cultivar'].unique()[:-1]\n",
    "for i in labels:\n",
    "    if not os.path.exists(os.path.join('./train', i)):\n",
    "        os.mkdir(os.path.join('./train', i))\n",
    "    if not os.path.exists(os.path.join('./vali', i)):\n",
    "        os.mkdir(os.path.join('./vali', i))\n",
    "    if not os.path.exists(os.path.join('./train_vali', i)):\n",
    "        os.mkdir(os.path.join('./train_vali', i))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "with open('./train_cultivar_mapping.csv', 'r') as f:\n",
    "    lines = f.readlines()[1:]\n",
    "    dict = {}\n",
    "    for i in lines:\n",
    "        tmp = i.split(',')\n",
    "        dict[tmp[0]] = tmp[1][:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# for i in os.listdir(os.path.join(data_dir, 'sorghum-id-fgvc-9/train_images')):\n",
    "#     file_name = dict[i]\n",
    "#     shutil.copy(os.path.join(data_dir, 'sorghum-id-fgvc-9/train_images', i), os.path.join('./train_vali', file_name))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# for i in os.listdir(os.path.join(data_dir, 'train_vali')):\n",
    "#     if not i.startswith('.'):\n",
    "#         category = os.listdir(os.path.join(data_dir, 'train_vali', i))\n",
    "#         vali = random.sample(category, int(len(category) * 0.1))\n",
    "#         for j in vali:\n",
    "#             shutil.copy(os.path.join(data_dir, 'train_vali', i, j), os.path.join(data_dir, 'vali', i))\n",
    "#         for j in category:\n",
    "#             if j not in vali:\n",
    "#                 shutil.copy(os.path.join(data_dir, 'train_vali', i, j), os.path.join(data_dir, 'train', i))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((512, 512)),\n",
    "        torchvision.transforms.CenterCrop((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "    ]),\n",
    "    'vali': torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "    ])\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root=os.path.join(data_dir, 'train'), transform=transform['train'])\n",
    "vali_dataset = torchvision.datasets.ImageFolder(root=os.path.join(data_dir, 'vali'), transform=transform['vali'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "vali_loader = torch.utils.data.DataLoader(vali_dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True, progress=True)\n",
    "for parm in model.parameters():\n",
    "    parm.requires_grad = False\n",
    "model.fc = torch.nn.Linear(torchvision.models.resnet50().fc.in_features, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "train epoch[1/1] loss:4.012:  37%|███▋      | 230/626 [29:50<52:10,  7.90s/it]  "
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "best_acc = 0\n",
    "print('Training...')\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss_count = 0\n",
    "    train_bar = tqdm(train_loader, file=sys.stdout)\n",
    "    for step, batch in enumerate(train_bar):\n",
    "        img, label = batch\n",
    "        optimizer.zero_grad()\n",
    "        img.to(device)\n",
    "        label.to(device)\n",
    "        output = model(img)\n",
    "        loss = loss_func(output, label)\n",
    "        loss_count += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss)\n",
    "\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(vali_loader, file=sys.stdout)\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "            val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "    val_accurate = acc / len(vali_dataset)\n",
    "    print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' % (epoch + 1, loss_count / len(train_loader), val_accurate))\n",
    "\n",
    "    if val_accurate > best_acc:\n",
    "        best_acc = val_accurate\n",
    "        torch.save(model.state_dict(), './FGVC_model.pth')\n",
    "\n",
    "print('Best Acc: {:.4f}'.format(best_acc))\n",
    "print('Training Finished!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}